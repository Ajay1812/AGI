{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_KEY')\n",
    "MODEL = input(\"Enter your model name: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "model = Ollama(model=MODEL)\n",
    "embeddings = OllamaEmbeddings(model=MODEL)\n",
    "# def embed(text):\n",
    "#     return embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = model | parser \n",
    "# chain.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load our pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='100 Machine Learning Interview Questions and\\nAnswers\\n1. Please Explain Machine Learning, Artificial Intelligence, And Deep Learning?\\nMachine learning is defined as a subset of Artificial Intelligence, and it contains the techniques\\nwhich enable computers to sort things out from the data and deliver Artificial Intelligence\\napplications. Artificial Intelligence (AI) is a branch of computer science that is mainly focused on\\nbuilding smart machines that can perform certain tasks that mainly require human intelligence. It\\nis the venture to replicate or simulate human intelligence in machines.\\nDeep learning can be defined as a class of machine learning algorithms in Artificial Intelligence\\nthat mainly uses multiple layers to cumulatively extract higher-level features from the given raw\\ninput.\\n2. How Difficult Is Machine Learning?\\nMachine Learning is huge and comprises a lot of things. Therefore, it will take more than six\\nmonths to learn Machine Learning if you spend at least 6-7 hours per day. If you have good\\nhands-on mathematical and analytical skills, then six months will be sufficient for you.\\n3. Can You Explain Kernel Trick In An SVM Algorithm?\\nA Kernel Trick is a method where the Non-Linear data is projected onto a bigger dimension\\nspace in order to make it easy to classify the data where it can be linearly divided by a plane.\\n4. Can You List Some Of The Popular Cross-Validation Techniques?\\n1.\\nHoldout Method: This kind of technique works by removing the part of the training data\\nset and sending the same to the model that was trained on the remaining data set to get\\nthe required predictions.\\n2.\\nK-Fold Cross-Validation: Here, the data is divided into k subsets so that every time, one\\namong the k subsets can be used as a validation set, and the other k-1 subsets are used\\nas the training set\\n3.\\nStratified K-Fold Cross-Validation: It works on imbalanced data.\\n4.\\nLeave-P-Out Cross-Validation: Here, we leave p data points out of the training data out\\nof the n data points, then we use the n-p samples to train the model and p points for the\\nvalidation set.\\n5. Differences Between The Bagging And Boosting Algorithms?', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 0}),\n",
       " Document(page_content='Bagging\\nBoosting\\nIt is a method that merges the same type of \\npredictions.\\nIt is a method that merges the different types \\nof predictions.\\nIt decreases the variance, not the bias\\nIt decreases the bias, not the variance.\\nEach and every model receives equal weight\\nModels are weighed based on performance.\\n6. What Are Kernels In SVM? Can You List Some Popular Kernels Used In SVM?\\nThe kernel is basically used to set mathematical functions that are used in the Support Vector\\nMachine by providing the window to manipulate the data. Kernel Function is used to transform\\nthe training set of data so that a non-linear decision surface will be transformed to a linear\\nequation in a bigger number of dimension spaces.\\nSome of the popular kernels used in SVM are:\\n1.\\nPolynomial kernel\\n2.\\nGaussian kernel\\n3.\\nGaussian radial basis function (RBF)\\n4.\\nLaplace RBF kernel\\n5.\\nHyperbolic tangent kernel\\n6.\\nSigmoid kernel\\n7.\\nBessel function of the first kind Kernel\\n8.\\nANOVA radial basis kernel\\n7. Can You Explain The OOB Error?\\nAn out-of-bag error called OBB error, also known as an out-of-bag estimate, is a technique to\\nmeasure the prediction error of random forests, boosted decision trees. Bagging mainly uses\\nsubsampling with replacement to create the training samples for the model to learn from them.\\n8. Can You Differentiate Between K-Means And KNN Algorithms?\\nK-Means\\nKNN algorithms\\nIt is unsupervised machine learning.\\nIt is supervised machine learning.\\nIt is a clustering machine learning algorithm.\\nIt is a classification or regression machine \\nlearning algorithm.\\nIts performance is slow.\\nIt performs much better.\\nIt is an eager learner.\\nIt is a lazy learner.', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 1}),\n",
       " Document(page_content='9. Explain The Term Variance Inflation Factor Mean?\\nVariance inflation factor known as VIF is a measure of the amount of multicollinearity in the\\ngiven set of multiple regression variables. The ratio here is calculated for each of the\\nindependent variables. A high VIF means that the associated independent variable is mostly\\ncollinear with the other variables in the model.\\n10. Explain SVM (Support Vector Machines) In Machine Learning?\\nSupport Vector Machine, known as SVM, is one of the most commonly used Supervised\\nLearning algorithms that is mainly used for Classification as well as Regression problems. It is\\nprimarily used for Classification problems in Machine Learning. The main aim of the SVM\\nalgorithm is to create the best decision boundary, which segregates n-dimensional space into\\nclasses so that one can easily put the new obtained data point in the correct category in the\\nfuture.\\n11. Differentiate Between Supervised And Unsupervised Machine Learning?\\nSupervised Model\\nUnsupervised Model\\nHere, the algorithm learns on a labeled \\ndataset,\\nHere, it provides unlabeled data.\\nHere, the models need to find the mapping \\nfunction that is used to map the input variable \\n(X) with the output variable (Y).\\nThe main aim of unsupervised learning is to \\nfind the structure and patterns from the given \\ninput data.\\n12. Explain The Terms Precision And Recall?\\nPrecision, also known as a positive predictive value, is defined as the fraction of relevant\\ninstances among the retrieved instances.\\nPrecision = TP/TP+FP\\nWhere TP is true positive\\nFP id False Positive\\nRecall, also known as sensitivity, is defined as the fraction of relevant instances that were\\nRetrieved.\\nRecall  = TP/TP+FP.\\nWhere TP is true positive\\nFP is False positive.\\n13. Differentiate Between L1 And L2 Regularization?', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 2}),\n",
       " Document(page_content='L1 Regularization\\nL2 Regularization\\nA regression model that makes use of the L1 \\nregularization process is called Lasso \\nRegression.\\nA regression model that makes use of the L1 \\nregularization process is called Ridge \\nRegression.\\nLasso Regression adds the absolute value of \\nthe magnitude of coefficient as a penalty term \\nto the loss function.\\nRidge regression adds the squared \\nmagnitude of coefficient as a penalty term to \\nthe loss function.\\nIt tries to estimate the median of the data.\\nIt tries to estimate the mean of the data.\\n14. Explain Fourier Transform?\\nThe Fourier transform is a way to split something up into a bunch of sine waves. In terms of\\nmathematics, The Fourier Transform is a process that can transform a signal into its respective\\nconstituent components and frequencies. Fourier transform is used not only in signal, radio,\\nacoustic, etc.\\n15. What Is The F1 Score? How To Use It?\\nThe F1-score combines both the precision and recall of a classifier into one single metric by\\ntaking the harmonic mean. It is used to compare the performances of two classifiers. For\\nexample, classifier X has a higher recall, and classifier Y  has higher precision. Now the\\nF1-scores calculated for both the classifiers will be used to predict which one produces the\\nbetter results.\\nThe F1 score can be calculated as\\n2(P*R)/(P+R)\\nWhere P is the precision.\\nR is the Recall of the classification model.\\nMachine Learning Interview Questions And Answers\\n16. Differentiate Between Type I And Type II Error?\\nType I Error\\nType II Error\\nIt is equivalent to a False positive.\\nIt is equivalent to a False negative\\nIt refers to non-acceptance of hypothesis\\nIt refers to the acceptance of the hypothesis\\nThere can be a rejection even with an \\nauthorized match.\\nThere can be an acceptance even with an \\nunauthorized match.\\n17. Can You Explain How A ROC Curve Works?', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 3}),\n",
       " Document(page_content='The  ROC curve is represented graphically by plotting the true positive rate (TPR) against the\\nFPR (False Positive rates). Where\\n1.\\nThe true positive rate can be defined as the proportion of observations that are predicted\\nto be positive out of all the given positive observations (TP/(TP + FN))\\n2.\\nThe false-positive rate is defined as the proportion of observations that are predicted\\nwrongly to be positive out of all the given negative observations.\\n(FP/(TN + FP))\\n18. Differentiate Between Deep Learning And Machine Learning?\\nDeep Learning\\nMachine Learning\\nIt is a subset of Machine Learning\\nIt is a superset of Deep Learning.\\nIt solves complex issues.\\nIt is used to learn new things.\\nIt is an evolution to Machine Learning.\\nIt is an evolution of AI.\\nHere, algorithms are largely self-depicted on \\nthe data analysis\\nAlgorithms are detected by the data analysts.\\n19. Can You Name The Different Machine Learning Algorithms?\\nDifferent machine learning algorithms are listed below:\\n1.\\nDecision trees,\\n2.\\nNaive Bayes,\\n3.\\nRandom forest\\n4.\\nSupport vector machine\\n5.\\nK-nearest neighbor,\\n6.\\nK-means clustering,\\n7.\\nGaussian mixture model,\\n8.\\nHidden Markov model etc.\\n20. What Is AI?\\nAI (Artificial intelligence) refers to the simulation of human intelligence in machines that are\\nprogrammed to reflect like humans and imitate their actions.\\nExamples: Face Detection and Recognition, Google Maps, and\\nRide-Hailing Applications, E-Payments.', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 4}),\n",
       " Document(page_content='21. How To Select Important Variables While Working On A Data Set?\\n1.\\nYou have to remove the correlated variables before selecting important variables.\\n2.\\nMake use of linear regression and select the variables based on their p values.\\n3.\\nUse Forward Selection, Stepwise Selection, and Backward Selection.\\n4.\\nUse Random Forest, Xgboost, and plot variable importance chart\\n5.\\nUse the Lasso Regression\\n6.\\nYou have to select top n features by measuring the information gain for the available set\\nof features.\\n22. Differentiate Between Causality And Correlation?\\nThe Causality explicitly applies to the cases where action A causes the outcome of action B.\\nCorrelation can simply be defined as a relationship. Where the actions of  A can relate to the\\nactions of B, but here it is not necessary for one event to cause the other event to happen.\\n23. What Is Overfitting?\\nOverfitting is a type of modeling error that results in the failure to predict or guess the future\\nobservations effectively or fit additional data in the model that already exists.\\n24. Explain The Terms Standard Deviation And Variance?\\nA standard deviation is defined as the number that specifies how spread out the values are. A\\nlow standard deviation represents that most of the numbers are close to the mean value. The\\nhigher standard deviation means that the values are spread out over, the wider range.\\nVariance in  Machine Learning is a type of error that occurs due to the model’s sensitivity to\\nsmall fluctuations in the given training set.\\n25. Explain Multilayer Perceptron And Boltzmann Machine?\\nA Multilayer Perceptron (MLP) is defined as a class of artificial neural networks that can\\ngenerate a set of outputs from the set of given inputs. An MLP consists of several layers of input\\nnodes that are connected as a directed graph between input and output layers.\\nThe main purpose of the Boltzmann Machine is to optimize the solution to a given problem. It is\\nmainly used to optimize the weights and quantity related to that specified problem.\\nMachine Learning Interview Questions And Answers\\n26. Explain The Term Bias?', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 5}),\n",
       " Document(page_content='Data bias in machine learning is defined as a type of error where certain elements of a given\\ndataset are weighted more heavily than others. A biased dataset will not accurately represent\\nthe model’s use case, and it results in low accuracy levels and analytical errors.\\n27. Name The Types Of Machine Learning?\\nThe types of machine learning are listed below:\\n1.\\nSupervised Learning\\n2.\\nUnsupervised Learning\\n3.\\nReinforcement Learning\\n28. Differentiate Between Classification And Regression?\\nClassification\\nRegression\\nIt is about predicting a label\\nIt is about predicting a quantity\\nHere, the data is labeled in one or multiple \\nclasses.\\nHere, you need to predict the quantity \\ncontinuously.\\nIt may predict a continuous value.\\nIt may predict a discrete value.\\nIt can be evaluated using accuracy.\\nIt can be evaluated using root mean squared \\nerror.\\n29. What Is A Confusion Matrix?\\nIn the field of machine learning, a confusion matrix also called an error matrix, is defined as a\\nspecific table layout that allows the user to visualize the performance of an algorithm, mainly a\\nsupervised learning one.\\n30. When Your Dataset Is Suffering From High Variance, How Would You Handle It?\\nFor datasets with high variance, we can make use of the bagging algorithm. The bagging\\nalgorithm splits the data into different subgroups with sampling replicated from random data.\\nOnce the data is split, using a training algorithm, the random data can be used to create rules.\\nThen we make use of the polling technique to gather all the predicted outcomes of the model.\\n31. Differentiate Between Inductive And Deductive Learning?\\nInductive Learning\\nDeductive Learning', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 6}),\n",
       " Document(page_content='It aims at developing a theory.\\nIt aims at testing an existing theory.\\nIt moves from the specific observations to the \\nbroad generalizations\\nIf there is no theory, you cannot conduct \\ndeductive research.\\nIt consists of three \\nstages,ObservationObserve a \\npatternDevelop a theory\\nIt consists of four stages:Start with an \\nexisting theoryFormulate a hypothesis based \\non existing theoryCollect data to test the \\nhypothesisAnalyze the results\\n32. Explain The Handling Of Corrupted Values In The Given Dataset?\\nThe below are the ways to handle missing data?\\n1.\\nRemove the rows with missing values.\\n2.\\nBuild another predictive model so that you can predict the missing values.\\n3.\\nUse a model in such a way that it can incorporate missing data.\\n4.\\nYou need to replace the missing data with the aggregated values.\\n5.\\nYou can predict the missing values.\\n6.\\ncreate an unknown category\\n33. Which Among These Is More Important Model Accuracy Or Model Performance?\\nModel accuracy is considered as the important characteristic of a Machine Language /AI model.\\nWhenever we discuss the performance of the model, we first clarify whether it is the model\\nscoring performance or Model training performance.\\nModel performance is improved by using distributed computing and parallelizing over the given\\nscored assets, but we need to carefully build the accuracy during the model training process.\\n34. What Is A Time Series?\\nThe time series in Machine learning is defined as a set of random variables that are ordered\\nwith respect to time. Time series are studied to interpret a phenomenon, identify the\\ncomponents of a trend, cyclicity,  and predict its future values.\\n35. Differentiate Between Entropy And Information Gain?\\nThe Information Gain is defined as the amount of information gained about a signal or random\\nvariable from observing another random variable.\\nEntropy can be defined as the average rate at which information is produced by the stochastic\\nsource of data, Or it can be defined as a measure of the uncertainty that is associated with a\\nrandom variable.', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 7}),\n",
       " Document(page_content='36. Differentiate Between Stochastic Gradient Descent (SGD) And Gradient Descent (GD)?\\nBatch Gradient Descent is involved in calculations over the full training set of each step, which\\nresults in a very slow process on very large training data. Hence, it becomes very expensive to\\ndo Batch GD. However, It is great for relatively smooth error manifolds. Also, it scales well with\\nthe number of features.\\nStochastic Gradient Descent tries to solve the primary problem in Batch Gradient descent that is\\nthe usage of entire training data to calculate the gradients as each step. SGD is stochastic in\\nnature means it picks up some  “random” instances of training data at each and every step, and\\nthen it computes the gradient making it faster as there are very little data to manipulate at one\\nshot,\\nBatch Gradient Descent\\nStochastic Gradient Descent\\nIt computes the gradient using the entire \\nTraining sample.\\nIt computes gradient using a single Training \\nsample.\\nIt can’t be suggested for huge training \\nsamples.\\nIt can be suggested for large training \\nsamples.\\nIt is deterministic in nature.\\nIt is sophisticated in nature.\\n37. Differentiate Between Gini Impurity And Entropy In A Decision Tree?\\nGini\\nEntropy\\nIt has values inside the interval [0, 0.5]\\nIt has values inside the interval [0, 1]\\nIt is more complex.\\nIt is not complex.\\nIts measurement is the probability of a \\nrandom sample that is being classified \\ncorrectly.\\nIt is a measurement to calculate the lack of \\ninformation,\\n38. Mention Some Of The Advantages And Disadvantages Of Decision Trees?\\nAdvantages of the decision tree:\\n1.\\nDecision trees require less effort for data preparation during the pre-processing when\\ncompared with other algorithms.\\n2.\\nA decision tree doesn’t require the normalization of data.\\n3.\\nIt does not require scaling of data.\\n4.\\nMissing values in the data do not affect the process of building a decision tree.\\n5.\\nA Decision tree model is very easy to explain to technical teams and stakeholders.', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 8}),\n",
       " Document(page_content='39. Can You Explain The Ensemble Learning Technique In Machine Learning?\\nEnsemble methods are the techniques used to create multiple models and combine them to\\nproduce enhanced results. Ensemble methods usually produce more precise solutions than a\\nsingle model would.\\nIn Ensemble Learning, we divide the training data set into multiple subsets, where each subset\\nis then used to build a separate model. Once the models are trained, they are then combined to\\npredict an outcome in such a way that there is a reduction in the variance of the output.\\nMachine Learning Interview Questions And Answers\\n40. Explain The Terms Collinearity And Multicollinearity?\\nMulticollinearity occurs when multiple independent variables are highly correlated with each\\nother in a regression model, which means that an independent variable can be predicted from\\nanother independent variable inside a regression model.\\nCollinearity mainly occurs when two predictor variables in a multiple regression have some\\ncorrelation.\\n41. Differentiate Between Random Forest And Gradient Boosting Machines?\\nLike random forests, gradient boosting is also a set of decision trees. The two primary\\ndifferences are:\\n1.\\nHow trees are built: Each tree in the random forest is built independently, whereas\\ngradient boosting builds only one tree at a time.\\n2.\\nCombining results: random forests combine results at the end of the process by\\naveraging. Whereas gradient boosting combines results along the path.\\n42. Explain The Terms Eigenvectors And Eigenvalues?\\nEigenvectors are unit vectors, meaning their length or magnitude is equal to 1.0. They are\\nreferred to as right vectors, which means a column vector.\\nEigenvalues are coefficients that are applied to eigenvectors that, in turn, give the vectors their\\nlength or magnitude.\\n43. Can You Explain Associative Rule Mining (ARM)?\\nAssociation rule mining (ARM) aims to find out the association rules that will satisfy the\\npredefined minimum support and confidence from a database. AMO is mainly used to reduce\\nthe number of association rules with the new fitness functions that can incorporate frequent\\nrules.\\n44. What Is A/B Testing?', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 9}),\n",
       " Document(page_content='A/B testing is defined as a basic randomized control experiment. It is used to compare two\\nversions of a variable to find out which one among them performs better in a controlled\\nenvironment.\\nA/B Testing can be best used to compare two models to check which one is the\\nbest-recommended product to a customer.\\n45. Explain Marginalisation And Its Process?\\nMarginalization is a method that requires the summing of the possible values of one variable to\\ndetermine the marginal contribution of another variable.\\nP(X=x) = ∑YP(X=x,Y)\\n46. What Is Cluster Sampling?\\nCluster sampling is defined as a type of sampling method. With cluster sampling, the\\nresearchers usually divide the population into separate groups or sets, known as clusters. Then,\\na random sample of clusters is picked from the population. Then the researcher conducts their\\nanalysis on the data from the collected sampled clusters.\\n47. Explain The Term“Curse Of Dimensionality”?\\nThe curse of dimensionality basically refers to the increase in the error with the increase in the\\nnumber of features. It can be referred to the fact that algorithms are vigorous to design in high\\ndimensions, and they often have a running time exponential in the dimensions.\\n48. Can You Name A Few Libraries In Python Used For Data Analysis And Scientific\\nComputations?\\n1.\\nNumPy\\n2.\\nSciPy\\n3.\\nPandas\\n4.\\nSciKit\\n5.\\nMatplotlib\\n6.\\nSeaborn\\n7.\\nBokeh\\n49. What Are Outliers? Mention The Methods To Deal With Outliers?\\nAn outlier can be defined as an object that deviates significantly from other objects. They can be\\ncaused by execution errors.\\nThe three main methods to deal with outliers are as follows:\\n1.\\nUnivariate method', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 10}),\n",
       " Document(page_content='2.\\nMultivariate method\\n3.\\nMinkowski error\\n50. List Some Popular Distribution Curves Along With Scenarios Where You Will Use Them In\\nAn Algorithm?\\nThe most popular distribution curves are:\\nUniform distribution can be defined as a probability distribution that has a constant probability.\\nExample: Rolling a single dice since it has multiple outcomes.\\nThe binomial distribution is defined as a probability with two possible outcomes only. Example: a\\ncoin toss. The result will either be heads or tails.\\nNormal distribution specifies how the values of a variable are distributed. Example: The height\\nof students in a classroom.\\nPoisson distribution helps to predict the probability of specific events that are happening when\\nyou know how often that event has occurred.\\nThe exponential distribution is mainly concerned with the amount of time until the specific event\\noccurs. Example: how long a car battery could last, in months.\\n51. Can You List The Assumptions For Data To Be Met Before Starting With Linear Regression?\\nThe assumptions to be met are:\\n1.\\nLinear relationship\\n2.\\nMultivariate normality\\n3.\\nNo or little multicollinearity\\n4.\\nNo auto-correlation\\n5.\\nHomoscedasticity\\n52. Explain The Term Variance Inflation Factor Mean?\\nVariance inflation factor that is VIF is defined as a measure of the amount of multicollinearity in a\\ngiven set of multiple regression variables.\\nMathematically, the Variance inflation factor for a regression model variable is equal to the ratio\\nof the final model variance to the variance of a model that comprises that single independent\\nvariable.\\nThis ratio is calculated for each of the independent variables. A high VIF represents that the\\nassociated independent variable is hugely collinear with the other variables in the model.\\n53. Can You Tell Us When The Linear Regression Line Stops Rotating Or Finds An Optimal\\nSpot Where It Is Fitted On Data?', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 11}),\n",
       " Document(page_content='The place where the highest RSquared value is found is where the line comes to rest.\\nRSquared usually represents the amount of variance that is captured by the virtual linear\\nregression line w.r.t the total variance captured by the dataset.\\n54. Can You Tell Us Which Machine Learning Algorithm Is Known As The Lazy Learner And\\nWhy It Is Called So?\\nKNN Machine Learning algorithm is called a lazy learner. K-NN is defined as a lazy learner\\nbecause it will not learn any machine-learned values or variables from the given training data,\\nbut dynamically it calculates the distance every time it wants to classify. Hence it memorizes the\\ntraining dataset instead.\\n55. Can You Tell Us What Could Be The Problem When The Beta Value For A Specific Variable\\nVaries Too Much In Each Subset When Regression Is Run On Various Subsets Of The Dataset?\\nThe variations in the beta values in every subset suggest that the dataset is heterogeneous. To\\novercome this problem, we use a different model for each of the clustered subsets of the given\\ndataset, or we use a non-parametric model like decision trees.\\n56. How To Choose A Classifier Based On A Training Set Data Size?\\nIf the training set is small in size, high bias or low variance models, for example, Naive Bayes\\ntends to perform better as they are less likely to overfit.\\nIf the training set is large in size, low bias or high variance models, for example, Logistic\\nRegression, tend to perform better as they can reflect more complicated relationships.\\n57. Differentiate Between Training Set And Test Set In A Machine Learning Model?\\nTraining set\\nTest set\\n70% of the total data is taken as the training \\ndataset.\\nThe remaining 30% is taken as a testing \\ndataset.\\nIt is implemented to build up a model.\\nIt is used to validate the model built.\\nIt is a labeled data used to train the model.\\nWe usually test without labeled data and then \\nverify the results with labels.\\n58. Explain A False Positive And False Negative And How Are They Significant?\\nA false positive is a concept where you receive a positive result for a given test when you\\nshould have actually received a negative result. It’s also called a “false alarm” or “false positive\\nerror.” It is basically used in the medical field, but it can also apply to software testing.\\nExamples of False positive:', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 12}),\n",
       " Document(page_content='1.\\nA pregnancy test is positive, where in fact, you are not pregnant.\\n2.\\nA cancer screening test is positive, but you do not have the disease.\\n3.\\nPrenatal tests are positive for Down’s Syndrome when your fetus does not have any\\ndisorder.\\n4.\\nVirus software on your system incorrectly identifies a harmless program as the malicious\\none.\\nA false negative is defined where a negative test result is wrong. In simple words, you get a\\nnegative test result, where you should have got a positive test result.\\nFor example, consider taking a pregnancy test, and you test as negative (not pregnant). But in\\nfact, you are pregnant.\\nThe false negative pregnancy test results due to taking the test too early, using the diluted urine,\\nor checking the results very soon. Just about every medical test has the risk of a false negative.\\n59. Explain The Term Semi-Supervised Machine Learning?\\nSemi-supervised learning is defined as an approach to machine learning that combines a less\\namount of labeled data with a huge amount of unlabeled data during the training process. It falls\\nbetween unsupervised learning and supervised learning.\\n60. Can You Tell Us The Applications Of Supervised Machine Learning In Modern Businesses?\\n1.\\nHealthcare Diagnosis\\n2.\\nFraud detection\\n3.\\nEmail spam detection\\n4.\\nSentimental analysis\\n61. Can You Differentiate Between Inductive Machine Learning And Deductive Machine\\nLearning?\\nInductive Machine Learning\\nDeductive Machine Learning\\nA \\n⋀\\n B \\n⊢\\n A → B (Induction)\\nA \\n⋀\\n (A –>B)\\n⊢\\n B(Deduction)\\nIt observes and learns from the set of \\ninstances, and then it draws the conclusion.\\nIt derives the conclusion first, and then it \\nworks on it based on the previous decision.\\nIt is a Statistical machine learning like KNN or \\nSVM,\\nMachine learning algorithm to deductive \\nreasoning using the decision tree.\\n62. What Is Random Forest In Machine Learning?', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 13}),\n",
       " Document(page_content='The random forest can be defined as a supervised learning algorithm that is used for\\nclassifications and regression. Similarly, the random forest algorithm creates decision trees on\\nthe data samples, and then it gets the prediction from each of the samples and finally selects\\nthe best one by means of voting.\\n63. Explain The Trade-Off Between Bias And Variance?\\nBias can be defined as the assumptions made by the model to make the target function easy to\\napproximate.\\nVariance is defined as the amount that the estimate of the target function will change given the\\ndifferent training data.\\nThe trade-off is defined as the tension between the error introduced by bias and variance.\\n64. Explain Pruning In Decision Trees, And How Is It Done?\\nPruning is a data compression process in machine learning and search algorithms that can\\nreduce the size of the decision trees by removing certain sections of the tree that are non-critical\\nand unnecessary to classify instances. A tree that is too huge risks overfitting the training data\\nand is poorly generalizing to the new samples.\\nPruning can take place as follows.\\n1.\\nTop-down fashion (It will travel the nodes and trim subtrees starting at the root)\\n2.\\nBottom-up fashion (It will start at the leaf nodes)\\nWe have reduced the error algorithm for the pruning of decision trees.\\n65. How Reduced Error Algorithms Work For Pruning In Decision Trees?\\nThe reduced error algorithm works as follows:\\n1.\\nIt considers each node for pruning.\\n2.\\nPruning = removing the subtree at that node, then make it a leaf and assign the major\\ncommon class at that node.\\n3.\\nA node is removed from the tree if the resulting tree performs worse than the original.\\n4.\\nNodes are removed iteratively by choosing the node in such a way that whose removal\\nmostly increases the accuracy of the decision tree on the graph.\\n5.\\nPruning continues to perform until further pruning is harmful.\\n6.\\nIt uses training, test sets, and validations. It is an effective approach if a vast amount of\\ndata is available.\\n66. Explain The Term Decision Tree Classification?\\nA decision tree builds classification models as a tree structure, with datasets broken up into\\nsmaller subsets while developing the decision tree; basically, it is a tree-like way with branches\\nand nodes defined. Decision trees handle both categorical and numerical data.', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 14}),\n",
       " Document(page_content='67. Explain Logistic Regression?\\nLogistic regression analysis is a technique used to examine the association of independent\\nvariables with one dichotomous dependent variable. This is in contrast to the linear regression\\nanalysis, where the dependent variable is a continuous variable.\\nEvery time the output of logistic regression is 0 or 1 with a threshold value of 0.5. Any value\\nabove 0.5 is taken as 1, and any point below 0.5 is taken as 0.\\n68. Name Some Methods Of Reducing Dimensionality?\\nSome of the methods of reducing dimensionality are given below:\\n1.\\nBy combining features with feature engineering\\n2.\\nRemoving collinear features\\n3.\\nusing algorithmic dimensionality reduction.\\n69. What Is A Recommendation System?\\nRecommendation systems mainly collect the customer data and auto analyze this data to\\ngenerate the customized recommendations for the customers. These systems mainly rely on\\nimplicit data like browsing history and recent purchases and explicit data like ratings provided by\\nthe customer.\\n70. Explain The K Nearest Neighbor Algorithm?\\nK-Nearest Neighbour is the simplest Machine Learning algorithm that is based on the\\nSupervised Learning technique. It assumes the similarity between the new case or data and the\\navailable cases, and it puts the new case into a category that is similar to that of the available\\ncategories.\\nFor example, we have an image of a creature that looks similar to that of a cat and a dog, but\\nwe want to know whether it is a cat or a dog. For this identification, we can make use of the\\nKNN algorithm, as it works on a similarity basis. The KNN model will find the similarities of the\\nnew data set to that of the cats and dogs images, and that is based on the similar features; it will\\nput it in either a cat or a dog category.\\n71. Considering A Given Long List Of Machine Learning Algorithms, Given A Data Set, How Do\\nThe Spam Filters Of The Email Will Be Fed With Hundreds Of Emails You Decide Which One To\\nUse?\\nChoosing an algorithm depends on the below-mentioned questions:\\n1.\\nHow much data you have, and is that continuous or categorical?\\n2.\\nIs the problem related to classification, clustering, association, or regression?', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 15}),\n",
       " Document(page_content='3.\\nIs it a Predefined variable (labeled), unlabeled, or a mix of both?\\n4.\\nWhat is the primary purpose?\\nBased on the above questions, one has to choose the right algorithm that suits their\\nrequirement.\\n72. Can You Tell Us How To Design An Email Spam Filter?\\n1.\\nThe spam filter of the email will be fed with hundreds of emails.\\n2.\\nEach of these emails  has a label: ‘spam’ or ‘not spam.’\\n3.\\nThe supervised machine learning algorithm will then identify which type of emails are\\nbeing marked as spam based on spam keywords like the lottery, no money, full refund,\\netc.\\n4.\\nThe next time an email hits the inbox, the spam filter will use statistical analysis and\\nalgorithms like Decision Trees and SVM to identify how likely the email is spam.\\n5.\\nIf the probability is high, then it will be labeled as spam, and the email will not hit your\\ninbox.\\n6.\\nBased on the accuracy of each of the models, we use the algorithm with the highest\\nreliability after testing all the given models.\\n73. How Can You Avoid Overfitting?\\nOverfitting is avoided by following the steps:\\n1.\\nCross-validation: The idea here is to use the initial training data to generate various\\nsmall train test spills. Where these test spills are used to tune the model.\\n2.\\nTrain with more data: Training with a lot of data can help the algorithms to detect the\\nsignals better.\\n3.\\nRemove feature: You can manually remove some of the features.\\n4.\\nEarly stopping: It refers to stopping the training process before the learner passes the\\nspecified point.\\n5.\\nRegularization: It refers to a broad range of techniques for artificially forcing the model to\\nbe simple.\\n6.\\nEnsembling: These are machine learning algorithms that combine predictions from\\nmultiple separate models.\\n74. Explain The Term Selection Bias In Machine Learning?\\nSelection bias takes place if a data set’s examples are chosen in such a way that it is not\\nreflective of their real-world distribution. Selection bias can take many various forms.\\n1.\\nCoverage bias: Data here is not selected in a representative manner.', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 16}),\n",
       " Document(page_content='Example: A model is trained in such a way to predict the future sales of a new product based on\\nthe phone surveys conducted with the sample of customers who bought the product.\\nConsumers who instead opted for buying a competing product were not surveyed, and as a\\nresult, this set of people were not represented in the training data.\\n2.\\nNon-response bias: Data here ends up being unrepresentative due to the participation\\ngaps in the collection of data processes.\\nExample:  A model is trained in such a way to predict the future sales of a new product based\\non the phone surveys conducted with a sample of customers who bought the product and with a\\nsample of customers who bought the competing product. Customers who bought the competing\\nproduct were 80% more expected to refuse to complete the survey, and their data were\\nunderrepresented in the sample.\\n3.\\nSampling bias:  Here, proper randomization is not used during the data collection\\nprocess.\\nExample: A model that is trained to predict the future sales of a new product based on the\\nphone surveys conducted with a sample of customers who bought the product and with a\\nsample of customers who bought a competing product. Instead of randomly targeting\\ncustomers, the surveyor chose the first 200 consumers that responded to their email, who might\\nhave been more eager about the product than the average purchasers.\\n75. Explain The Types Of Supervised Learning?\\nSupervised learning is of two types, namely,\\n1.\\nRegression: It is a kind of Supervised Learning that learns from the given  Labelled\\nDatasets, and then it is able to predict the continuous-valued output for the new data that\\nis given to the algorithm. It is used in cases where an output requirement is a number\\nlike money or height etc. Some popular Supervised Learning algorithms are Linear\\nRegression, Logistic Regression.\\n2.\\nClassification: It is a kind of learning where the algorithm needs to be mapped to the new\\ndata that is obtained from any one of the two classes that we have in the dataset. The\\nclasses have to be mapped to either 1 or 0, which in real-life translates to the  ‘Yes’ or\\n‘No.’ The output will have to be either one of the classes, and it should not be a number\\nas it was in the case of Regression. Some of the most well-known algorithms are\\nDecision trees, Naive Bayes Classifier, Support vector Algorithms.\\n76. What Vanishing Gradient Descent?\\nIn Machine Learning, we encounter the Vanishing Gradient Problem while training the Neural\\nNetworks with gradient-based methods like Back Propagation. This problem makes it hard to\\ntune and learn the parameters of the earlier layers in the given network.\\nThe vanishing gradients problem can be taken as one example of the unstable behavior that we\\nmay encounter when training the deep neural network.', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 17}),\n",
       " Document(page_content='It describes a situation where the deep multilayer feed-forward network or the recurrent neural\\nnetwork is not able to propagate the useful gradient information from the given output end of the\\nmodel back to the layers close to the input end of the model.\\n77. Can You Name The Proposed Methods To Overcome The Vanishing Gradient Problem?\\nThe methods proposed to overcome the vanishing gradient problems are:\\n1.\\nMulti-level hierarchy\\n2.\\nThe long short – term memory\\n3.\\nFaster hardware\\n4.\\nResidual neural networks (ResNets)\\n5.\\nReLU\\n78. Differentiate Between Data Mining And Machine Learning?\\nData Mining\\nMachine Learning\\nIt extracts useful information from a large \\namount of data.\\nIt introduces algorithms from data as well as \\nfrom past experience.\\nIt is used to understand the flow of data.\\nIt teaches the computers to learn and \\nunderstand from the data flow.\\nIt has huge databases with unstructured \\ndata.\\nIt has existing data as well as algorithms.\\nIt requires human interference in it.\\nNo need for the human effort required after \\ndesign\\nModels are developed  using data mining \\ntechnique\\nmachine-learning algorithm can be used in \\nthe decision tree, neural networks, and some \\nother parts of artificial intelligence\\nIt is more of research using methods like \\nmachine learning.\\nIt is self-learned and trains the system to do \\nintelligent tasks.\\n79. Name The Different Algorithm Techniques In Machine Learning?\\nThe different algorithm techniques in machines learning are listed below:\\n1.\\nUnsupervised Learning\\n2.\\nSemi-supervised Learning\\n3.\\nTransduction', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 18}),\n",
       " Document(page_content='4.\\nReinforcement Learning\\n5.\\nLearning to Learn\\n6.\\nSupervised Learning\\n80.  Explain The Function Of ‘Unsupervised Learning?\\n1.\\nIt has to find clusters of the data.\\n2.\\nFind the low-dimensional representations of the data\\n3.\\nTo find interesting directions in data\\n4.\\nTo calculate interesting coordinates and correlations.\\n5.\\nFind novel observations or database cleaning.\\n81. Explain The Term Classifier In Machine Learning?\\nA classifier in machine learning is defined as an algorithm that automatically categorizes the\\ndata into one or more of a group of “classes.” One of the common examples is an email\\nclassifier that can scan the emails to filter them by the given class labels: Spam or Not Spam.\\nWe have five types of classification algorithms, namely,\\n1.\\nDecision Tree\\n2.\\nNaive Bayes Classifier\\n3.\\nK-Nearest Neighbors\\n4.\\nSupport Vector Machines\\n5.\\nArtificial Neural Networks\\n82. What Are Genetic Algorithms ?\\nGenetic algorithms are defined as stochastic search algorithms which can act on a population of\\npossible solutions. Genetic algorithms are mainly used in artificial intelligence to search a space\\nof potential solutions to find one who can solve the problem.\\n83. Can You Name The Area Where Pattern Recognition Can Be Used?\\n1.\\nSpeech Recognition\\n2.\\nStatistics\\n3.\\nInformal Retrieval\\n4.\\nBioinformatics\\n5.\\nData Mining\\n6.\\nComputer Vision', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 19}),\n",
       " Document(page_content='84. Explain The Term Perceptron In Machine Learning?\\nA Perceptron is defined as an algorithm for supervised learning of binary classifiers. This\\nalgorithm enables the neurons to learn and processes the elements in the given training set one\\nat a time. There are two types of Perceptrons, namely.\\n1.\\nSingle-layer\\n2.\\nMultilayer.\\n85. What Is Isotonic Regression?\\nIsotonic regression is used iteratively to fit ideal distances to protect the relative dissimilarity\\norder. Isotonic regression is also used in the probabilistic classification to balance the predicted\\nprobabilities of the supervised machine learning models.\\n86. What Are Bayesian Networks?\\nA Bayesian network can be defined as a probabilistic graphical model that presents a set of\\nvariables and their conditional dependencies through a DAG (directed acyclic graph).\\nFor example, a Bayesian network would represent the probabilistic relationships between the\\ndiseases and their symptoms. Given the specific symptoms, the network can be used to\\ncompute the possibilities of the presence of different diseases.\\n87. Can You Explain The Two Components Of The Bayesian Logic Program?\\nThe bayesian logic program mainly comprises two components.\\n1.\\nThe first component is the logical one: it comprises a set of Bayesian Clauses that\\ncaptures the qualitative structure of the domain.\\n2.\\nThe second component is quantitative: it encodes the quantitative information about the\\ndomain.\\n88.  What Is An Incremental Learning Algorithm In An Ensemble?\\nThe incremental learning method is defined as the ability of an algorithm to learn from new data\\nthat is available after the classifier has already been generated from the already available\\ndataset.\\n89. Name The Components Of Relational Evaluation Techniques?\\nThe components of the relational evaluation technique are listed below:\\n1.\\nData Acquisition\\n2.\\nGround Truth Acquisition\\n3.\\nCross-Validation Technique', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 20}),\n",
       " Document(page_content='4.\\nQuery Type\\n5.\\nScoring Metric\\n6.\\nSignificance Test\\n90. Can You Explain The Bias-Variance Decomposition Of Classification Error In The Ensemble\\nMethod?\\nThe expected error of the learning algorithm can be divided into bias and variance. A bias term\\nis a  measure of how closely the average classifier produced by the learning algorithm matches\\nwith the target function.  The variance term is a  measure of how much the learning algorithm’s\\nprediction fluctuates for various training sets.\\n91. Name The Different Methods For Sequential Supervised Learning?\\nThe different methods for sequential supervised learning are given below:\\n1.\\nRecurrent sliding windows\\n2.\\nHidden Markow models\\n3.\\nMaximum entropy Markow models\\n4.\\nConditional random fields\\n5.\\nGraph transformer networks\\n6.\\nSliding-window methods\\n92. What Is Batch Statistical Learning?\\nA training dataset is divided into one or more batches. When all the training samples are used in\\nthe creation of one batch, then that learning algorithm is known as batch gradient descent.\\nWhen the given batch is the size of one sample, then the learning algorithm is called stochastic\\ngradient descent.\\n93.  Can You Name The Areas In Robotics And Information Processing Where Sequential\\nPrediction Problem Arises?\\nThe areas in robotics and information processing where sequential prediction problem arises\\nare given below\\n1.\\nStructured prediction\\n2.\\nModel-based reinforcement learning\\n3.\\nImitation Learning\\n94. Name The Different Categories You Can Categorize The Sequence Learning Process?', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 21}),\n",
       " Document(page_content='The different categories where you can categorize the sequence learning process are listed\\nbelow:\\n1.\\nSequence generation\\n2.\\nSequence recognition\\n3.\\nSequential decision\\n4.\\nSequence prediction\\n95. What Is Sequence Prediction?\\nSequence prediction aims to predict elements of the sequence on the basis of the preceding\\nelements.\\nA prediction model is trained with the set of training sequences. On training, the model is used\\nto perform sequence predictions. A prediction comprises predicting the next items of a\\nsequence. This task has a number of applications like web page prefetching, weather\\nforecasting, consumer product recommendation, and stock market prediction.\\nExamples of sequence prediction problems include:\\n1.\\nWeather Forecasting. Given a sequence of observations about the particular weather\\nover a period of time, it predicts the expected tomorrow’s weather.\\n2.\\nStock Market Prediction. Given a sequence of movements of the security over a period\\nof time, it predicts the next movement of the security.\\n3.\\nProduct Recommendation. Given a sequence of the last purchases of a customer, it\\npredicts the next purchase of a customer.\\n96.  Explain  PAC Learning?\\nProbably approximately correct, i.e., PAC learning is defined as a theoretical framework used for\\nanalyzing the generalization error of the learning algorithm in terms of its error on a given\\ntraining set and some measures of the complexity. The main goal here is to typically show that\\nan algorithm can achieve low generalization error with high probability.\\n97. What Are PCA, KPCA, And ICA, And What Are They Used For?\\nPrincipal Components Analysis(PCA): It linearly transforms the original inputs into the new\\nuncorrelated features.\\nKernel-based Principal Component Analysis(KCPA): It is a nonlinear PCA developed by using\\nthe kernel method.\\nIndependent Component Analysis(ICA): In ICA, the original inputs are linearly transformed into\\ncertain features that are mutually statistically independent.\\n98.  Explain The Three Stages Of Building A Model In Machine Learning?\\nThe three stages are:', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 22}),\n",
       " Document(page_content='1.\\nModel Building\\n2.\\nModel Testing\\n3.\\nApplying the model\\n99. Explain The Term Hypothesis In ML?\\nMachine Learning, especially supervised learning, can be specified as the desire to use the\\navailable data to learn a function that best maps the inputs to outputs.\\nTechnically, this problem is called function approximation, where we are approximating an\\nunknown target function that we assume as it exists that can best map the given inputs to\\noutputs on all possible considerations from the problem domain.\\nAn example of the model that approximates the target function and performs the mappings of\\ninputs to the outputs is known as the hypothesis in machine learning.\\nThe choice of algorithm and the configuration of the algorithm define the space of possible\\nhypotheses that the model may constitute.\\n100. Explain The Terms Eepoch, Eentropy, Bbias, And Vvariance In Machine Learning?\\nEpoch is a term widely used in machine learning that indicates the number of passes of the\\nwhole training dataset that the machine learning algorithm has completed. If the batch size is\\nthe entire training dataset, then the number of epochs is defined as the number of iterations.\\nEntropy in Machine learning can be defined as the measure of disorder or uncertainty. The main\\ngoal of machine learning models and Data Scientists, in general, is to decrease uncertainty.\\nData bias is a type of error in which certain elements of a dataset are more heavily weighted\\nthan others.\\nVariance is defined as the amount that the estimate of the target function will change if a\\ndifferent training data set was used. The target function is usually estimated from the training\\ndata by the machine learning algorithm.', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 23})]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"100-Machine-Learning-Interview-Questions-and-Answers.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below. If you can't \n",
      "answer this question, reply \"I Don't Know\".\n",
      "\n",
      "Context:Here is some context\n",
      "\n",
      "Question:Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer this question, reply \"I Don't Know\".\n",
    "\n",
    "Context:{context}\n",
    "\n",
    "Question:{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\",question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'context': {'title': 'Context', 'type': 'string'},\n",
       "  'question': {'title': 'Question', 'type': 'string'}}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Ajay.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"context\": \"The name I was given was Ajay \",\n",
    "        \"question\": \"What is my name?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Doc Array in memory search\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(\n",
    "    pages,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A/B testing is defined as a basic randomized control experiment. It is used to compare two\\nversions of a variable to find out which one among them performs better in a controlled\\nenvironment.\\nA/B Testing can be best used to compare two models to check which one is the\\nbest-recommended product to a customer.\\n45. Explain Marginalisation And Its Process?\\nMarginalization is a method that requires the summing of the possible values of one variable to\\ndetermine the marginal contribution of another variable.\\nP(X=x) = ∑YP(X=x,Y)\\n46. What Is Cluster Sampling?\\nCluster sampling is defined as a type of sampling method. With cluster sampling, the\\nresearchers usually divide the population into separate groups or sets, known as clusters. Then,\\na random sample of clusters is picked from the population. Then the researcher conducts their\\nanalysis on the data from the collected sampled clusters.\\n47. Explain The Term“Curse Of Dimensionality”?\\nThe curse of dimensionality basically refers to the increase in the error with the increase in the\\nnumber of features. It can be referred to the fact that algorithms are vigorous to design in high\\ndimensions, and they often have a running time exponential in the dimensions.\\n48. Can You Name A Few Libraries In Python Used For Data Analysis And Scientific\\nComputations?\\n1.\\nNumPy\\n2.\\nSciPy\\n3.\\nPandas\\n4.\\nSciKit\\n5.\\nMatplotlib\\n6.\\nSeaborn\\n7.\\nBokeh\\n49. What Are Outliers? Mention The Methods To Deal With Outliers?\\nAn outlier can be defined as an object that deviates significantly from other objects. They can be\\ncaused by execution errors.\\nThe three main methods to deal with outliers are as follows:\\n1.\\nUnivariate method', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 10}),\n",
       " Document(page_content='84. Explain The Term Perceptron In Machine Learning?\\nA Perceptron is defined as an algorithm for supervised learning of binary classifiers. This\\nalgorithm enables the neurons to learn and processes the elements in the given training set one\\nat a time. There are two types of Perceptrons, namely.\\n1.\\nSingle-layer\\n2.\\nMultilayer.\\n85. What Is Isotonic Regression?\\nIsotonic regression is used iteratively to fit ideal distances to protect the relative dissimilarity\\norder. Isotonic regression is also used in the probabilistic classification to balance the predicted\\nprobabilities of the supervised machine learning models.\\n86. What Are Bayesian Networks?\\nA Bayesian network can be defined as a probabilistic graphical model that presents a set of\\nvariables and their conditional dependencies through a DAG (directed acyclic graph).\\nFor example, a Bayesian network would represent the probabilistic relationships between the\\ndiseases and their symptoms. Given the specific symptoms, the network can be used to\\ncompute the possibilities of the presence of different diseases.\\n87. Can You Explain The Two Components Of The Bayesian Logic Program?\\nThe bayesian logic program mainly comprises two components.\\n1.\\nThe first component is the logical one: it comprises a set of Bayesian Clauses that\\ncaptures the qualitative structure of the domain.\\n2.\\nThe second component is quantitative: it encodes the quantitative information about the\\ndomain.\\n88.  What Is An Incremental Learning Algorithm In An Ensemble?\\nThe incremental learning method is defined as the ability of an algorithm to learn from new data\\nthat is available after the classifier has already been generated from the already available\\ndataset.\\n89. Name The Components Of Relational Evaluation Techniques?\\nThe components of the relational evaluation technique are listed below:\\n1.\\nData Acquisition\\n2.\\nGround Truth Acquisition\\n3.\\nCross-Validation Technique', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 20}),\n",
       " Document(page_content='The  ROC curve is represented graphically by plotting the true positive rate (TPR) against the\\nFPR (False Positive rates). Where\\n1.\\nThe true positive rate can be defined as the proportion of observations that are predicted\\nto be positive out of all the given positive observations (TP/(TP + FN))\\n2.\\nThe false-positive rate is defined as the proportion of observations that are predicted\\nwrongly to be positive out of all the given negative observations.\\n(FP/(TN + FP))\\n18. Differentiate Between Deep Learning And Machine Learning?\\nDeep Learning\\nMachine Learning\\nIt is a subset of Machine Learning\\nIt is a superset of Deep Learning.\\nIt solves complex issues.\\nIt is used to learn new things.\\nIt is an evolution to Machine Learning.\\nIt is an evolution of AI.\\nHere, algorithms are largely self-depicted on \\nthe data analysis\\nAlgorithms are detected by the data analysts.\\n19. Can You Name The Different Machine Learning Algorithms?\\nDifferent machine learning algorithms are listed below:\\n1.\\nDecision trees,\\n2.\\nNaive Bayes,\\n3.\\nRandom forest\\n4.\\nSupport vector machine\\n5.\\nK-nearest neighbor,\\n6.\\nK-means clustering,\\n7.\\nGaussian mixture model,\\n8.\\nHidden Markov model etc.\\n20. What Is AI?\\nAI (Artificial intelligence) refers to the simulation of human intelligence in machines that are\\nprogrammed to reflect like humans and imitate their actions.\\nExamples: Face Detection and Recognition, Google Maps, and\\nRide-Hailing Applications, E-Payments.', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 4}),\n",
       " Document(page_content='It describes a situation where the deep multilayer feed-forward network or the recurrent neural\\nnetwork is not able to propagate the useful gradient information from the given output end of the\\nmodel back to the layers close to the input end of the model.\\n77. Can You Name The Proposed Methods To Overcome The Vanishing Gradient Problem?\\nThe methods proposed to overcome the vanishing gradient problems are:\\n1.\\nMulti-level hierarchy\\n2.\\nThe long short – term memory\\n3.\\nFaster hardware\\n4.\\nResidual neural networks (ResNets)\\n5.\\nReLU\\n78. Differentiate Between Data Mining And Machine Learning?\\nData Mining\\nMachine Learning\\nIt extracts useful information from a large \\namount of data.\\nIt introduces algorithms from data as well as \\nfrom past experience.\\nIt is used to understand the flow of data.\\nIt teaches the computers to learn and \\nunderstand from the data flow.\\nIt has huge databases with unstructured \\ndata.\\nIt has existing data as well as algorithms.\\nIt requires human interference in it.\\nNo need for the human effort required after \\ndesign\\nModels are developed  using data mining \\ntechnique\\nmachine-learning algorithm can be used in \\nthe decision tree, neural networks, and some \\nother parts of artificial intelligence\\nIt is more of research using methods like \\nmachine learning.\\nIt is self-learned and trains the system to do \\nintelligent tasks.\\n79. Name The Different Algorithm Techniques In Machine Learning?\\nThe different algorithm techniques in machines learning are listed below:\\n1.\\nUnsupervised Learning\\n2.\\nSemi-supervised Learning\\n3.\\nTransduction', metadata={'source': '100-Machine-Learning-Interview-Questions-and-Answers.pdf', 'page': 18})]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter('question') | retriever,\n",
    "        \"question\": itemgetter('question')\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# chain.invoke({\"question\":\"Projetcs?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects?'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemgetter(\"question\")({\"question\":\"projects?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Can You Name The Different Machine Learning Algorithms?\n",
      "Answer: I Don't Know.\n",
      "\n",
      "Question: What Is Overfitting?\n",
      "Answer: Answer based on provided context:\n",
      "\n",
      "Overfitting is a type of modeling error that results in the failure to predict or guess the future observations effectively or fit additional data in the model that already exists.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\"Can You Name The Different Machine Learning Algorithms?\",\n",
    "             \"What Is Overfitting?\"]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {chain.invoke({'question': question})}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
